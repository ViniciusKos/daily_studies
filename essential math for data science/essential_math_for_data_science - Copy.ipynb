{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Type II error is the likelihood failing to reject a false null hypothesis. Don't detected an effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2691857437994568, 644.6406810715571, 161.51144627967406)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"regressao_Q1.csv\")\n",
    "\n",
    "# Prepare the features and target variable\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Create the ElasticNet model with specified parameters\n",
    "model = ElasticNet(alpha=1.0, l1_ratio=0.01, random_state=0)\n",
    "\n",
    "# Prepare cross-validation with 5 folds\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "# Perform cross-validation and calculate the mean squared error\n",
    "scores = cross_val_score(model, X, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "\n",
    "# The cross_val_score function returns negative mean squared errors, we need to make them positive\n",
    "mse_scores = -scores\n",
    "\n",
    "# Calculate the mean of MSE scores for both training and validation sets\n",
    "mean_mse = np.mean(mse_scores)\n",
    "\n",
    "# We cannot exactly calculate the sum of squared errors directly from the mean of MSE because\n",
    "# the number of samples in each fold might be different if the dataset size is not divisible by 5.\n",
    "# Therefore, we will perform cross-validation manually to get the sum of squared errors for each fold.\n",
    "\n",
    "# Lists to store sum of squared errors for each fold\n",
    "train_sse = []\n",
    "val_sse = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    # Split data into training and validation sets\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate the sum of squared errors for training and validation sets\n",
    "    train_sse.append(np.sum((model.predict(X_train) - y_train)**2))\n",
    "    val_sse.append(np.sum((model.predict(X_val) - y_val)**2))\n",
    "\n",
    "# Calculate the average of the sum of squared errors for both sets\n",
    "mean_train_sse = np.mean(train_sse)\n",
    "mean_val_sse = np.mean(val_sse)\n",
    "\n",
    "mean_mse, mean_train_sse, mean_val_sse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.876851378187404, 0.8790619764973195, 0.876851378187404)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "df_classification = pd.read_csv(\"classificacao_Q2.csv\")\n",
    "# Prepare the features and target variable\n",
    "X_class = df_classification.drop('target', axis=1)\n",
    "y_class = df_classification['target']\n",
    "\n",
    "# Create the Logistic Regression model with L2 regularization\n",
    "model_class = LogisticRegression(C=0.1, penalty='l2', solver='liblinear', random_state=0)\n",
    "\n",
    "# Prepare stratified cross-validation with 10 folds\n",
    "cv_class = StratifiedKFold(n_splits=10, shuffle=False)\n",
    "\n",
    "# Perform cross-validation and calculate AUC\n",
    "auc_scores = cross_val_score(model_class, X_class, y_class, cv=cv_class, scoring='roc_auc')\n",
    "\n",
    "# Calculate the mean AUC scores for both training and validation sets\n",
    "mean_auc = np.mean(auc_scores)\n",
    "\n",
    "# To get the AUC for training sets, we have to fit the model on each fold and calculate it\n",
    "train_auc_scores = []\n",
    "valid_auc_scores = []\n",
    "for train_index, val_index in cv_class.split(X_class, y_class):\n",
    "    # Split data into training and validation sets\n",
    "    X_train, X_val = X_class.iloc[train_index], X_class.iloc[val_index]\n",
    "    y_train, y_val = y_class.iloc[train_index], y_class.iloc[val_index]\n",
    "    \n",
    "    # Fit the model on the training data\n",
    "    model_class.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate the AUC on the training set\n",
    "    train_auc_scores.append(roc_auc_score(y_train, model_class.predict_proba(X_train)[:, 1]))\n",
    "    valid_auc_scores.append(roc_auc_score(y_val, model_class.predict_proba(X_val)[:, 1]))\n",
    "\n",
    "\n",
    "mean_train_auc = np.mean(train_auc_scores)\n",
    "mean_valid_auc_scores = np.mean(valid_auc_scores)\n",
    "\n",
    "mean_auc, mean_train_auc, mean_valid_auc_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_train_auc = np.mean(train_auc_scores)\n",
    "\n",
    "mean_auc, mean_train_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.396551281458314"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X=np.random.normal(2.4,0.04,100)\n",
    "d_9 = np.percentile(X,50)\n",
    "d_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "p:\\Python\\GitHub\\daily_studies\\env_studies\\lib\\site-packages\\sklearn\\cluster\\_agglomerative.py:1006: FutureWarning: Attribute `affinity` was deprecated in version 1.2 and will be removed in 1.4. Use `metric` instead\n",
      "  warnings.warn(\n",
      "p:\\Python\\GitHub\\daily_studies\\env_studies\\lib\\site-packages\\sklearn\\cluster\\_agglomerative.py:1006: FutureWarning: Attribute `affinity` was deprecated in version 1.2 and will be removed in 1.4. Use `metric` instead\n",
      "  warnings.warn(\n",
      "p:\\Python\\GitHub\\daily_studies\\env_studies\\lib\\site-packages\\sklearn\\cluster\\_agglomerative.py:1006: FutureWarning: Attribute `affinity` was deprecated in version 1.2 and will be removed in 1.4. Use `metric` instead\n",
      "  warnings.warn(\n",
      "p:\\Python\\GitHub\\daily_studies\\env_studies\\lib\\site-packages\\sklearn\\cluster\\_agglomerative.py:1006: FutureWarning: Attribute `affinity` was deprecated in version 1.2 and will be removed in 1.4. Use `metric` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4,\n",
       " 0.589374033016901,\n",
       " {2: 0.5199002748643055,\n",
       "  3: 0.5663652051962086,\n",
       "  4: 0.589374033016901,\n",
       "  5: 0.5725689189611636})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('agrupamento.csv')\n",
    "\n",
    "# Since we don't know the exact features, we'll assume the entire data is to be used for clustering\n",
    "X = df\n",
    "\n",
    "# Dictionary to store the silhouette scores for different number of clusters\n",
    "silhouette_scores = {}\n",
    "\n",
    "# Testing cluster sizes from 2 to 5\n",
    "for n_clusters in range(2, 6):\n",
    "    clustering = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='average')\n",
    "    cluster_labels = clustering.fit_predict(X)\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    silhouette_scores[n_clusters] = silhouette_avg\n",
    "\n",
    "# Find the number of clusters with the highest silhouette score\n",
    "best_n_clusters = max(silhouette_scores, key=silhouette_scores.get)\n",
    "best_silhouette_score = silhouette_scores[best_n_clusters]\n",
    "\n",
    "best_n_clusters, best_silhouette_score, silhouette_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_studies",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
